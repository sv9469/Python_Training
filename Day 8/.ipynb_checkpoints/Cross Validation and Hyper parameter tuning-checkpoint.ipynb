{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation and Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- What is the drawback of using the **train/test split** procedure for model evaluation?\n",
    "- How does **K-fold cross-validation** overcome this limitation?\n",
    "- How can cross-validation be used for selecting **tuning parameters**, choosing between **models**, and selecting **features**?\n",
    "- What are some possible **improvements** to cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of model evaluation procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** Need a way to choose between machine learning models\n",
    "\n",
    "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
    "\n",
    "**Initial idea:** Train and test on the same data\n",
    "\n",
    "- But, maximizing **training accuracy** rewards overly complex models which **overfit** the training data\n",
    "\n",
    "**Alternative idea:** Train/test split\n",
    "\n",
    "- Split the dataset into two pieces, so that the model can be trained and tested on **different data**\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance\n",
    "- But, it provides a **high variance** estimate since changing which observations happen to be in the testing set can significantly change testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read titanic data\n",
    "df = pd.read_csv(\"titanic_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col = ['Age', 'Fare', 'Pclass_2', 'Pclass_3', 'Sex_male','Embarked_Q', 'Embarked_S', 'family_members_1', \n",
    "             'family_members_2','family_members_>=3']\n",
    "target_col = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[train_col]\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8059701492537313\n"
     ]
    }
   ],
   "source": [
    "# use train/test split with different random_state values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Create a RandomForest Classifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=21, max_features = 3, max_depth = 3, random_state = 1)\n",
    "\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7686567164179104\n"
     ]
    }
   ],
   "source": [
    "# use train/test split with different random_state values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#Try 1,123\n",
    "\n",
    "#Create a RandomForest Classifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=21, max_features = 3, max_depth = 3, random_state = 1)\n",
    "\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What if we created a bunch of train/test splits, calculated the testing accuracy for each, and averaged the results together?\n",
    "\n",
    "**Answer:** That's the essense of cross-validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is K-fold cross-validation?\n",
    "\n",
    "K-Fold CV is where a given data set is split into a K number of sections/folds where each fold is used as a testing set at some point. Lets take the scenario of 5-Fold cross validation(K=5). Here, the data set is split into 5 folds. In the first iteration, the first fold is used to test the model and the rest are used to train the model. In the second iteration, 2nd fold is used as the testing set while the rest serve as the training set. This process is repeated until each fold of the 5 folds have been used as the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram of **5-fold cross-validation:**\n",
    "\n",
    "![5-fold cross-validation](images/cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing cross-validation to train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of **cross-validation:**\n",
    "\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    "- More \"efficient\" use of data (every observation is used for both training and testing)\n",
    "\n",
    "Advantages of **train/test split:**\n",
    "\n",
    "- Runs K times faster than K-fold cross-validation\n",
    "- Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. K can be any number, but **K=10** is generally recommended\n",
    "2. For classification problems, **stratified sampling** is recommended for creating the folds\n",
    "    - Each response class should be represented with equal proportions in each of the K folds\n",
    "    - scikit-learn's `cross_val_score` function does this by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation example: model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Compare the best model between logistic regression, decision tree and Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81111111 0.78651685 0.7752809  0.85393258 0.80898876 0.78651685\n",
      " 0.7752809  0.7752809  0.80898876 0.82022472]\n",
      "0.8002122347066167\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with Logistic regression\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "scores = cross_val_score(lr, X,y, cv = 10, scoring = 'accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8025468164794007"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10-fold cross-validation with decision tree\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(max_depth = 5)\n",
    "cross_val_score(clf_tree, X,y, cv = 10, scoring = 'accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8160174781523096"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10-fold cross-validation with Randomforest\n",
    "clf_rf = RandomForestClassifier(n_estimators=21, max_features = 3, max_depth = 3, random_state = 1)\n",
    "\n",
    "cross_val_score(clf_rf, X, y, cv=10, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation example: parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Select the best tuning parameters (**number of trees**) for Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74444444 0.82022472 0.78651685 0.87640449 0.87640449 0.82022472\n",
      " 0.82022472 0.75280899 0.84269663 0.82022472]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation\n",
    "clf_rf = RandomForestClassifier(n_estimators=21, max_features = 3, max_depth = 3, random_state = 1)\n",
    "\n",
    "scores = cross_val_score(clf_rf, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8160174781523096\n"
     ]
    }
   ],
   "source": [
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7261173533083646, 0.7755555555555556, 0.7643820224719101, 0.8081023720349563, 0.7912858926342073, 0.7958177278401998, 0.8103370786516855, 0.8081148564294631, 0.798039950062422, 0.8024843945068664, 0.7991510611735331, 0.8092259675405742, 0.8058926342072409, 0.8115106117353308, 0.8193757802746567, 0.8126466916354558, 0.8126342072409487, 0.8115106117353308, 0.8148689138576779, 0.8171410736579275, 0.8160174781523096, 0.8126466916354558, 0.8070536828963796, 0.8081772784019975, 0.8115355805243446, 0.8137827715355807, 0.8115480649188515, 0.8126591760299625, 0.8126716604244694, 0.8093008739076156]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of n_estimators for random forest\n",
    "ntree_range = list(range(1, 31))\n",
    "ntree_scores = []\n",
    "for k in ntree_range:\n",
    "    clf_rf = RandomForestClassifier(n_estimators=k, max_features = 3, max_depth = 3, random_state = 1)\n",
    "    scores = cross_val_score(clf_rf, X, y, cv=10, scoring='accuracy')\n",
    "    ntree_scores.append(scores.mean())\n",
    "print(ntree_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross-Validated Accuracy')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of Number of Trees (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(ntree_range, ntree_scores)\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements to cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeated cross-validation**\n",
    "\n",
    "- Repeat cross-validation multiple times (with **different random splits** of the data) and average the results\n",
    "- More reliable estimate of out-of-sample performance by **reducing the variance** associated with a single trial of cross-validation\n",
    "\n",
    "**Creating a hold-out set**\n",
    "\n",
    "- \"Hold out\" a portion of the data **before** beginning the model building process\n",
    "- Locate the best model using cross-validation on the remaining data, and test it **using the hold-out set**\n",
    "- More reliable estimate of out-of-sample performance since hold-out set is **truly out-of-sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter tuning using `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allows you to define a **grid of parameters** that will be **searched** using K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "# define the parameter values that should be searched\n",
    "ntree_range = list(range(1, 31))\n",
    "print(ntree_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}\n"
     ]
    }
   ],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_estimators=ntree_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(max_features = 3, max_depth = 3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the grid\n",
    "grid = GridSearchCV(clf_rf, param_grid, cv=10, scoring='accuracy', return_train_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can set **`n_jobs = -1`** to run computations in parallel (if supported by your computer and OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=RandomForestClassifier(max_depth=3, max_features=3,\n",
       "                                              random_state=1),\n",
       "             param_grid={'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                          22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the grid with data\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.726117</td>\n",
       "      <td>0.036861</td>\n",
       "      <td>{'n_estimators': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775556</td>\n",
       "      <td>0.030374</td>\n",
       "      <td>{'n_estimators': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.764382</td>\n",
       "      <td>0.060558</td>\n",
       "      <td>{'n_estimators': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.808102</td>\n",
       "      <td>0.029757</td>\n",
       "      <td>{'n_estimators': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.791286</td>\n",
       "      <td>0.056044</td>\n",
       "      <td>{'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.795818</td>\n",
       "      <td>0.043790</td>\n",
       "      <td>{'n_estimators': 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.810337</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>{'n_estimators': 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.808115</td>\n",
       "      <td>0.039829</td>\n",
       "      <td>{'n_estimators': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.798040</td>\n",
       "      <td>0.037854</td>\n",
       "      <td>{'n_estimators': 9}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.802484</td>\n",
       "      <td>0.033680</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.799151</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>{'n_estimators': 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.809226</td>\n",
       "      <td>0.029556</td>\n",
       "      <td>{'n_estimators': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.805893</td>\n",
       "      <td>0.033681</td>\n",
       "      <td>{'n_estimators': 13}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.811511</td>\n",
       "      <td>0.037453</td>\n",
       "      <td>{'n_estimators': 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.819376</td>\n",
       "      <td>0.039257</td>\n",
       "      <td>{'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.812647</td>\n",
       "      <td>0.036743</td>\n",
       "      <td>{'n_estimators': 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.812634</td>\n",
       "      <td>0.035096</td>\n",
       "      <td>{'n_estimators': 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.811511</td>\n",
       "      <td>0.041907</td>\n",
       "      <td>{'n_estimators': 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.814869</td>\n",
       "      <td>0.036313</td>\n",
       "      <td>{'n_estimators': 19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.817141</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.816017</td>\n",
       "      <td>0.042502</td>\n",
       "      <td>{'n_estimators': 21}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.812647</td>\n",
       "      <td>0.039715</td>\n",
       "      <td>{'n_estimators': 22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.807054</td>\n",
       "      <td>0.042835</td>\n",
       "      <td>{'n_estimators': 23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.808177</td>\n",
       "      <td>0.048534</td>\n",
       "      <td>{'n_estimators': 24}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.811536</td>\n",
       "      <td>0.046030</td>\n",
       "      <td>{'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.813783</td>\n",
       "      <td>0.048525</td>\n",
       "      <td>{'n_estimators': 26}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.811548</td>\n",
       "      <td>0.045379</td>\n",
       "      <td>{'n_estimators': 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.812659</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>{'n_estimators': 28}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.812672</td>\n",
       "      <td>0.043742</td>\n",
       "      <td>{'n_estimators': 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.041379</td>\n",
       "      <td>{'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score                params\n",
       "0          0.726117        0.036861   {'n_estimators': 1}\n",
       "1          0.775556        0.030374   {'n_estimators': 2}\n",
       "2          0.764382        0.060558   {'n_estimators': 3}\n",
       "3          0.808102        0.029757   {'n_estimators': 4}\n",
       "4          0.791286        0.056044   {'n_estimators': 5}\n",
       "5          0.795818        0.043790   {'n_estimators': 6}\n",
       "6          0.810337        0.028974   {'n_estimators': 7}\n",
       "7          0.808115        0.039829   {'n_estimators': 8}\n",
       "8          0.798040        0.037854   {'n_estimators': 9}\n",
       "9          0.802484        0.033680  {'n_estimators': 10}\n",
       "10         0.799151        0.036400  {'n_estimators': 11}\n",
       "11         0.809226        0.029556  {'n_estimators': 12}\n",
       "12         0.805893        0.033681  {'n_estimators': 13}\n",
       "13         0.811511        0.037453  {'n_estimators': 14}\n",
       "14         0.819376        0.039257  {'n_estimators': 15}\n",
       "15         0.812647        0.036743  {'n_estimators': 16}\n",
       "16         0.812634        0.035096  {'n_estimators': 17}\n",
       "17         0.811511        0.041907  {'n_estimators': 18}\n",
       "18         0.814869        0.036313  {'n_estimators': 19}\n",
       "19         0.817141        0.039683  {'n_estimators': 20}\n",
       "20         0.816017        0.042502  {'n_estimators': 21}\n",
       "21         0.812647        0.039715  {'n_estimators': 22}\n",
       "22         0.807054        0.042835  {'n_estimators': 23}\n",
       "23         0.808177        0.048534  {'n_estimators': 24}\n",
       "24         0.811536        0.046030  {'n_estimators': 25}\n",
       "25         0.813783        0.048525  {'n_estimators': 26}\n",
       "26         0.811548        0.045379  {'n_estimators': 27}\n",
       "27         0.812659        0.043556  {'n_estimators': 28}\n",
       "28         0.812672        0.043742  {'n_estimators': 29}\n",
       "29         0.809301        0.041379  {'n_estimators': 30}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the results as a pandas DataFrame\n",
    "import pandas as pd\n",
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1}\n",
      "0.7261173533083646\n"
     ]
    }
   ],
   "source": [
    "# examine the first result\n",
    "print(grid.cv_results_['params'][0])\n",
    "print(grid.cv_results_['mean_test_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8193757802746567\n",
      "{'n_estimators': 15}\n",
      "RandomForestClassifier(max_depth=3, max_features=3, n_estimators=15,\n",
      "                       random_state=1)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching multiple parameters simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Example:** tuning `max_depth` and `n_estimators` for a `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter values that should be searched\n",
    "ntree_range = list(range(7, 22))\n",
    "depth_range = list(range(3, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], 'max_depth': [3, 4, 5, 6, 7]}\n"
     ]
    }
   ],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_estimators=ntree_range, max_depth=depth_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(max_features = 3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=RandomForestClassifier(max_features=3, random_state=1),\n",
       "             param_grid={'max_depth': [3, 4, 5, 6, 7],\n",
       "                         'n_estimators': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                                          17, 18, 19, 20, 21]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate and fit the grid\n",
    "%time\n",
    "grid = GridSearchCV(clf_rf, param_grid, cv=10, scoring='accuracy', return_train_score=False)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810337</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.808115</td>\n",
       "      <td>0.039829</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798040</td>\n",
       "      <td>0.037854</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 9}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.802484</td>\n",
       "      <td>0.033680</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.799151</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 11}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.831735</td>\n",
       "      <td>0.051075</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.827241</td>\n",
       "      <td>0.047568</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.828377</td>\n",
       "      <td>0.051271</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.828377</td>\n",
       "      <td>0.049518</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.825006</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 21}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score                                params\n",
       "0          0.810337        0.028974   {'max_depth': 3, 'n_estimators': 7}\n",
       "1          0.808115        0.039829   {'max_depth': 3, 'n_estimators': 8}\n",
       "2          0.798040        0.037854   {'max_depth': 3, 'n_estimators': 9}\n",
       "3          0.802484        0.033680  {'max_depth': 3, 'n_estimators': 10}\n",
       "4          0.799151        0.036400  {'max_depth': 3, 'n_estimators': 11}\n",
       "..              ...             ...                                   ...\n",
       "70         0.831735        0.051075  {'max_depth': 7, 'n_estimators': 17}\n",
       "71         0.827241        0.047568  {'max_depth': 7, 'n_estimators': 18}\n",
       "72         0.828377        0.051271  {'max_depth': 7, 'n_estimators': 19}\n",
       "73         0.828377        0.049518  {'max_depth': 7, 'n_estimators': 20}\n",
       "74         0.825006        0.049064  {'max_depth': 7, 'n_estimators': 21}\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the results\n",
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8373283395755304\n",
      "{'max_depth': 7, 'n_estimators': 11}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the best parameters to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train your model using all data and the best known parameters\n",
    "clf_rf = RandomForestClassifier(max_depth = 7,n_estimators = 11, max_features = 3, random_state = 1)\n",
    "clf_rf.fit(X, y)\n",
    "\n",
    "# make a prediction on out-of-sample data\n",
    "clf_rf.predict([X.loc[0,:].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shortcut: GridSearchCV automatically refits the best model using all of the data\n",
    "grid.predict([X.loc[0,:].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing computational expense using `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Searching many different parameters at once may be computationally infeasible\n",
    "- `RandomizedSearchCV` searches a subset of the parameters, and you control the computational \"budget\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "param_dist = dict(n_estimators=ntree_range, max_depth=depth_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Important:** Specify a continuous distribution (rather than a list of values) for any continous parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(max_features = 3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.820462</td>\n",
       "      <td>0.039048</td>\n",
       "      <td>{'n_estimators': 17, 'max_depth': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.822709</td>\n",
       "      <td>0.038969</td>\n",
       "      <td>{'n_estimators': 18, 'max_depth': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.812634</td>\n",
       "      <td>0.035096</td>\n",
       "      <td>{'n_estimators': 17, 'max_depth': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.814881</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>{'n_estimators': 11, 'max_depth': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.832834</td>\n",
       "      <td>0.048023</td>\n",
       "      <td>{'n_estimators': 10, 'max_depth': 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.814869</td>\n",
       "      <td>0.036313</td>\n",
       "      <td>{'n_estimators': 12, 'max_depth': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.822734</td>\n",
       "      <td>0.041011</td>\n",
       "      <td>{'n_estimators': 19, 'max_depth': 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.819326</td>\n",
       "      <td>0.036266</td>\n",
       "      <td>{'n_estimators': 14, 'max_depth': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.823858</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.814869</td>\n",
       "      <td>0.036313</td>\n",
       "      <td>{'n_estimators': 19, 'max_depth': 3}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score                                params\n",
       "0         0.820462        0.039048  {'n_estimators': 17, 'max_depth': 4}\n",
       "1         0.822709        0.038969  {'n_estimators': 18, 'max_depth': 4}\n",
       "2         0.812634        0.035096  {'n_estimators': 17, 'max_depth': 3}\n",
       "3         0.814881        0.038901  {'n_estimators': 11, 'max_depth': 5}\n",
       "4         0.832834        0.048023  {'n_estimators': 10, 'max_depth': 7}\n",
       "5         0.814869        0.036313  {'n_estimators': 12, 'max_depth': 5}\n",
       "6         0.822734        0.041011  {'n_estimators': 19, 'max_depth': 6}\n",
       "7         0.819326        0.036266  {'n_estimators': 14, 'max_depth': 5}\n",
       "8         0.823858        0.041992  {'n_estimators': 20, 'max_depth': 6}\n",
       "9         0.814869        0.036313  {'n_estimators': 19, 'max_depth': 3}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_iter controls the number of searches\n",
    "rand = RandomizedSearchCV(clf_rf, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5, return_train_score=False)\n",
    "rand.fit(X, y)\n",
    "pd.DataFrame(rand.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8328339575530587\n",
      "{'n_estimators': 10, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.828, 0.833, 0.828, 0.834, 0.836, 0.836, 0.834, 0.836, 0.833, 0.833, 0.833, 0.837, 0.825, 0.828, 0.837, 0.832, 0.833, 0.836, 0.833, 0.836]\n"
     ]
    }
   ],
   "source": [
    "# run RandomizedSearchCV 5 times (with n_iter=10) and record the best score\n",
    "best_scores = []\n",
    "for _ in range(20):\n",
    "    rand = RandomizedSearchCV(clf_rf, param_dist, cv=10, scoring='accuracy', n_iter=10, return_train_score=False)\n",
    "    rand.fit(X, y)\n",
    "    best_scores.append(round(rand.best_score_, 3))\n",
    "print(best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- scikit-learn documentation: [Cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html), [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- scikit-learn issue on GitHub: [MSE is negative when returned by cross_val_score](https://github.com/scikit-learn/scikit-learn/issues/2439)\n",
    "- Section 5.1 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (11 pages) and related videos: [K-fold and leave-one-out cross-validation](https://www.youtube.com/watch?v=nZAM5OXrktY&list=PL5-da3qGB5IA6E6ZNXu7dp89_uv8yocmf) (14 minutes), [Cross-validation the right and wrong ways](https://www.youtube.com/watch?v=S06JpVoNaA0&list=PL5-da3qGB5IA6E6ZNXu7dp89_uv8yocmf) (10 minutes)\n",
    "- Scott Fortmann-Roe: [Accurately Measuring Model Prediction Error](http://scott.fortmann-roe.com/docs/MeasuringError.html)\n",
    "- Machine Learning Mastery: [An Introduction to Feature Selection](http://machinelearningmastery.com/an-introduction-to-feature-selection/)\n",
    "- Harvard CS109: [Cross-Validation: The Right and Wrong Way](https://github.com/cs109/content/blob/master/lec_10_cross_val.ipynb)\n",
    "- Journal of Cheminformatics: [Cross-validation pitfalls when selecting and assessing regression and classification models](http://www.jcheminf.com/content/pdf/1758-2946-6-10.pdf)\n",
    "- scikit-learn documentation: [Grid search](http://scikit-learn.org/stable/modules/grid_search.html), [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "- Timed example: [Comparing randomized search and grid search](http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html)\n",
    "- scikit-learn workshop by Andreas Mueller: [Video segment on randomized search](https://youtu.be/0wUF_Ov8b0A?t=17m38s) (3 minutes), [related notebook](https://github.com/amueller/pydata-nyc-advanced-sklearn/blob/master/Chapter%203%20-%20Randomized%20Hyper%20Parameter%20Search.ipynb)\n",
    "\n",
    "- Paper by Yoshua Bengio: [Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
